A common assumption is that open models are inherently transparent models. But does this hold?

Other frameworks, such as Stanford’s FMTI, have found that open science models tend to demonstrate stronger transparency practices around development and deployment. To explore this relationship in the current dataset, transparency scores were analyzed across different model accessibility types—from fully closed to open weight releases.

A clear trend emerges:
- API-only models show the lowest median transparency, with many scoring between 0 and 2. This suggests that models accessible only through APIs—while widely deployed—often share little about their training data or compute.

- Hosted access (no API) and unreleased models score slightly higher and display more variation, but still fall short of full transparency.

- In contrast, open weights models—whether unrestricted, non-commercial, or research-restricted—have higher median scores and greater consistency in reporting key inputs.

- Notably, models with restricted-use open weights (typically for research purposes) showed the highest median transparency, although this group may include a smaller number of high-disclosure cases.

These findings reflect broader dynamics: In commercial settings, limited transparency may reflect efforts to protect intellectual property or maintain a competitive edge. In research-driven releases, transparency is often prioritized due to norms around openness, reproducibility, and public trust.
