*The landscape of AI data transparency* visual explorer was built as part of my Master’s dissertation, in collaboration with the Open Data Institute (ODI), to support their AI Data Transparency Index (AIDTI) and broader work on data-centric AI. The project started with a simple but urgent question: how accessible and consistent is the information that AI developers share about the building blocks of their models—things like training data, compute, and parameter counts?

With regulations like the EU AI Act on the horizon, which will require developers to disclose this kind of upstream information, I wanted to understand what’s already available in the public domain. 

I used model metadata compiled by Epoch AI to explore how transparency information is (or isn’t) made available, and to surface patterns across a few key dimensions. I selected a set of relevant and consistently reported fields as proxies for transparency—recognizing that the presence or absence of this information doesn’t capture every nuance, but still offers meaningful insight into current disclosure practices. Importantly, since the dataset is built from public sources, it likely reflects what is easiest to collect or infer—rather than what developers deliberately chose to highlight. 

The goal was to turn this data into something more accessible: an interactive, visual tool that helps make sense of complex model development practices—especially for those without a technical background.


---