Here we explore the general distribution and variation of the transparency scores, with a more granular breakdown by organization types.

Industry and academia developers are the most prolific in the dataset, and both show broad variability in transparency. Models from these groups span the entire scale—from fully transparent (score of 4) to completely opaque (score of 0) —indicating that transparency is not consistent within these sectors. This suggests the presence of both leaders and laggards in disclosure practices. 

Academic institutions, seen as champions of open research, surprisingly reveal transparency patterns comparable to industry. This shift may reflect inconsistent reporting norms and changing incentive structures that de-prioritize thorough documentation in favor of rapid output or competitive edge.

In contrast, research collectives and cross-sector collaborations stand out for their higher median transparency scores and more consistent practices, with fewer low-scoring models. While these groups represent a smaller share of the dataset, their models are more likely to report key training inputs—potentially reflecting stronger norms or shared commitments to openness.

Government and public sector developers fall somewhere in the middle, with a moderate range of transparency and more variability than collaborative efforts. The “Unknown” category is small but scattered across the scale, hinting at occasional gaps in organizational metadata itself.

Together, these patterns show that no organization type guarantees transparency, but collaborative and research-driven entities tend to be more consistent and higher-scoring overall. This points to the importance of institutional norms and incentives in shaping disclosure practices—not just sector. 
