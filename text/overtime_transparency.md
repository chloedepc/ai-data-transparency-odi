The timeline visual explores temporal trends across organizations and regions. The top chart tracks changes in the average transparency score over time, broken down by region, while the bottom chart provides a component-level breakdown of training, data, dataset size, compute, and parameters. 

These visualizations help identify whether transparency documentation practices are improving and which specific factors are driving either progress or decline.

1. Average Transparency Score Over Time

    - Transparency improved steadily from 2016 to 2021, peaking around 2021-2022 across most regions. 
    - Since then, scores have generally declined across all regions, with some regions seeing sharp drops by 2024.
    - Cross-regional collaborations and South Asia maintained higher scores longer than other regions, while North America and East Asia show notable declines post-2022.
    - Different regions exhibit distinct cycles, which may be linked to local regulations, funding norms, or competitive pressures, though all regions saw a dip post-2022. 
    - This recent decline may reflect a shift toward closed releases, growing commercialization, or delayed reporting, as data from 2024–2025 is partial and may be incomplete.


2. Component-Level Transparency Over Time

    - Parameter count has remained the most consistently reported inpu over the years
    - Training dataset size, training compute, and especially training data peaked between 2020-2022 but have since declined sharply.
    - The decline could be linked to the race to commercialize larger models and increased secrecy around proprietary datasets
    - Training data disclosure now shows the steepest decline–indicating a return to opacity on this critical and sensitive input
    - These trends signal a regression in upstream transparency, despite growing awareness and regulation efforts


3. Organization-Specific Trends

    - Industry-academia collaborations show mixed results: While transparency in parameters and training compute has improved in recent years, training data and dataset size disclosures have dropped. This could be due to fewer models in 2024 and 2025, which affects the overall trend. 
    - Academia shows regional differences:
    - Europe and Central Asia have improved transparency since 2021. 
    - However, most other regions, including North America and East Asia, have seen a decline
    - Dataset size and training compute transparency have declined the most, while training data and parameters have seen less of a drop
    - In industry, transparency has declined across all regions since 2022, with all key components showing lower reporting. This is significant because model counts have remained steady for this category, meaning the decline is likely due to less transparency in reporting. 
