Now that we’ve seen how overall transparency scores vary across models, this section takes a closer look at what’s actually being reported. By breaking the composite score down into its four components—training compute, dataset size, training data, and parameters—we can uncover which transparency practices are most common, and where gaps persist.

1. By Developer Region:

- South Asia and MENA regions show high reporting of training compute and parameters—but lower consistency in dataset-level transparency.
- North America and Europe & Central Asia report more even scores, but none reach high levels across all four components.
- Training data is the least reported component across nearly all regions, especially in MENA, where it’s lowest overall.
- These patterns suggest regional variation may be shaped by regulatory context, research norms, or resource access—but also reflect sample size differences in the dataset that require cautious interpretation.


2. By Developer Organization Type:

- Research collectives lead on nearly all components, especially parameters and compute, with transparency scores often over 90%.
- Academia and industry have consistently low scores, especially on training data, suggesting institutional challenges in disclosing data inputs.
- Cross-sector collaborations show strong scores across most dimensions, particularly compute and parameters, likely benefiting from pooled resources or shared transparency norms.
- The training data gap is widespread, particularly among industry–academia partnerships—possibly reflecting IP sensitivities or unclear ownership.


3. By Model Accessibility:

- Open weights (restricted use) models are the most consistently transparent across all components, especially on training data and parameters.
- API access and hosted models show the lowest levels of transparency, with <40% disclosure on training data and dataset size.
- Unreleased models sometimes report well on parameters and compute—but rarely disclose training data, suggesting that access alone doesn’t predict input-level transparency.
- Across accessibility types, parameters are the most commonly reported component—while training data remains the most opaque.
